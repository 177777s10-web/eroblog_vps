#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FANZA(素人:videoc) サンプル画像だけを厳格収集:
- 対象ホスト: pics.dmm.co.jp / awsimgsrc.dmm.co.jp
- 対象パス  : /digital/amateur/<CID>/<CID>js-###.(jpg|jpeg|webp|png)
- それ以外(アイコン類、他CID、ポスターjm/jp単体)は除外
"""
import argparse, json, sys, re, time
from pathlib import Path
from urllib.parse import urlparse
from playwright.sync_api import sync_playwright, TimeoutError

UA = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/141.0 Safari/537.36"
BASE = "https://video.dmm.co.jp/amateur/content/?id={cid}"
ALLOW_HOSTS = ("pics.dmm.co.jp","awsimgsrc.dmm.co.jp")

def norm(u:str)->str:
    return (u or "").split("?",1)[0].split("#",1)[0]

def is_sample_of_cid(u:str, cid:str)->bool:
    u = norm(u)
    try:
        pr = urlparse(u)
    except:
        return False
    if pr.netloc not in ALLOW_HOSTS:
        return False
    # /digital/amateur/<cid>/<cid>js-###.ext のみ許可
    pat = re.compile(rf"/digital/amateur/{re.escape(cid)}/.*?/{re.escape(cid)}js-\d+\.(jpg|jpeg|webp|png)$", re.I)
    return bool(pat.search(pr.path))

def dedupe_keep_order(seq):
    seen = set()
    out = []
    for x in seq:
        if x not in seen:
            seen.add(x)
            out.append(x)
    return out

def agree_age(page):
    try:
        h1 = (page.locator("h1").first.inner_text(timeout=1500) or "")
        if "年齢認証" in h1:
            for sel in ["text=同意する","text=はい","text=I Agree"]:
                btn = page.locator(sel).first
                if btn.count():
                    btn.click(timeout=2000)
                    page.wait_for_load_state("networkidle", timeout=15000)
                    break
    except:  # noqa
        pass

def collect_image_urls(page):
    urls = set()
    # <img> の src
    for el in page.locator("img").all():
        try:
            u = el.get_attribute("src") or ""
            if u: urls.add(norm(u))
        except:
            pass
    # <source> の srcset
    for el in page.locator("source").all():
        try:
            ss = (el.get_attribute("srcset") or "").strip()
            for part in ss.split(","):
                u = part.strip().split(" ",1)[0]
                if u: urls.add(norm(u))
        except:
            pass
    return list(urls)

def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--cid", required=True)
    ap.add_argument("--out", required=True)
    ap.add_argument("--url_opt", default=None)
    ap.add_argument("--headless", default="true")
    ap.add_argument("--timeout", type=int, default=60000)
    ap.add_argument("--storage", default="dmm_storage_state.json")
    args = ap.parse_args()

    cid = args.cid.strip()
    url = args.url_opt or BASE.format(cid=cid)

    headless = str(args.headless).lower() not in ("0","false","no")

    with sync_playwright() as pw:
        br = pw.chromium.launch(headless=headless)
        ctx = br.new_context(user_agent=UA, storage_state=args.storage)
        page = ctx.new_page()
        try:
            page.goto(url, wait_until="domcontentloaded", timeout=args.timeout)
            agree_age(page)
            page.wait_for_load_state("networkidle", timeout=args.timeout)
        except TimeoutError:
            pass

        raw = collect_image_urls(page)
        # CID厳格フィルタ
        kept = [u for u in raw if is_sample_of_cid(u, cid)]
        kept = dedupe_keep_order(sorted(kept))  # 安定化

        out = {
            "cid": cid,
            "url": url,
            "sample_images": kept,
            "found": len(kept),
            "notes": [
                f"dom_total={len(raw)}",
                "filter=strict_cid_js_series",
                f"engine=chromium","headless="+str(headless)
            ]
        }
        Path(args.out).parent.mkdir(parents=True, exist_ok=True)
        Path(args.out).write_text(json.dumps(out, ensure_ascii=False, indent=2), encoding="utf-8")

        ctx.close(); br.close()

if __name__ == "__main__":
    main()
